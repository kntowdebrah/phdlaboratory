{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66aba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "#optional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180c4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114, 9)\n",
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([780, 9])\n",
      "y_train has shape: torch.Size([780, 1])\n",
      "x_test has shape: torch.Size([334, 9])\n",
      "y_test has shape: torch.Size([334, 1])\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwabe\\AppData\\Local\\Temp\\ipykernel_3264\\3750535070.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(lambda x:x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    #delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs , train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def heart_disease_data():\n",
    "    data = pd.read_csv('framingham.csv')\n",
    "    \n",
    "    #drop rows with  missing values\n",
    "    data = data.dropna()\n",
    "  \n",
    "    #drop some features\n",
    "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", 'diabetes','diaBP','BMI'])\n",
    "    \n",
    "    grouped = data.groupby('TenYearCHD')\n",
    "    data = grouped.apply(lambda x:x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "    \n",
    "    #extract labels\n",
    "    y = torch.tensor(data['TenYearCHD'].values).float().unsqueeze(1)\n",
    "    data = data.drop(columns='TenYearCHD')\n",
    "    data = (data - data.mean())/data.std()\n",
    "\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "def random_data(m=1024, n=2):\n",
    "    #data separable by the line y=x\n",
    "    x_train = torch.random(m,n)\n",
    "    x_test = torch.random(m//2, n)\n",
    "    y_train = (x_train[:,0] >= x_train[:,1]).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:,0] >= x_test[:,1]).float().unsqueeze(0).t()\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    " \n",
    " #You can use whatever data you want without modification to the tutorial\n",
    " #x_train, y_train, x_test, y_test = random_data()\n",
    " \n",
    "x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d09217a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a logistic Regression Model\n",
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef11cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "\n",
    "#use gradient descient with learning_rate = 1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a350112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1 : 0.8504331707954407\n",
      "Loss at epoch 2 : 0.6863384246826172\n",
      "Loss at epoch 3 : 0.6358115077018738\n",
      "Loss at epoch 4 : 0.6193529367446899\n",
      "Loss at epoch 5 : 0.6124349236488342\n"
     ]
    }
   ],
   "source": [
    "#define \n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs = EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f'Loss at epoch {e} : {loss.data}')\n",
    "    return model \n",
    "\n",
    "model = train(model, optim, criterion, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aeb1b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 0.703592836856842\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y-out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f'Accuracy on plain test_set: {plain_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78273076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing it the modern way\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ae50725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4238, 16)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "heart_disease_df = pd.read_csv('framingham.csv')\n",
    "heart_disease_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bfdad52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3656, 16)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data preparation \n",
    "heart_disease_df = heart_disease_df.dropna()\n",
    "heart_disease_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1f5f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping some columns (Features)\n",
    "heart_disease_df = heart_disease_df.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a8da227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwabe\\AppData\\Local\\Temp\\ipykernel_3264\\993874501.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  heart_disease_df = grouped.apply(lambda x:x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "grouped =heart_disease_df.groupby('TenYearCHD')\n",
    "heart_disease_df = grouped.apply(lambda x:x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1deb54f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 9)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease_df['TenYearCHD'].values.astype(float)\n",
    "x = heart_disease_df.drop(columns=['TenYearCHD'])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03dfd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing\n",
    "x = (x - x.mean())/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "690f40a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 9)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "877850f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xo_train, xo_test, yo_train, yo_test =train_test_split(x,y, random_state=42, test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "31a4cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "xo_train has shape: (779, 9)\n",
      "yo_train has shape: (779,)\n",
      "xo_test has shape: (335, 9)\n",
      "yo_test has shape: (335,)\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "print(\"############# Data summary #############\")\n",
    "print(f\"xo_train has shape: {xo_train.shape}\")\n",
    "print(f\"yo_train has shape: {yo_train.shape}\")\n",
    "print(f\"xo_test has shape: {xo_test.shape}\")\n",
    "print(f\"yo_test has shape: {yo_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encrypted Evaluation\n",
    "class EncryptedLR:\n",
    "\n",
    "    def __init__(self,torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "\n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "\n",
    "eelr = EncryptedLR(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcf22f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_eval.global_scale = 2**20\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "420b5bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test-set took 1 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_test = [ts.ckks_vector(ctx_eval,x.tolist()) for x in x_test]\n",
    "t_end = time()\n",
    "print(f'Encryption of the test-set took {int(t_end - t_start)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12953df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time()\n",
    "\n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        #encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        #plain comparison\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(out-y) < 0.5:\n",
    "            correct+=1\n",
    "\n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
    "    return correct / len(x_test)\n",
    "    \n",
    "    encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
    "    diff_accuracy = plain_accuracy - encrypted_accuracy \n",
    "\n",
    "    print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "    if diff_accuracy < 0:\n",
    "        print(\"Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac752557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyqtvirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
